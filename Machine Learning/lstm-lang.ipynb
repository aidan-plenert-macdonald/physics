{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Classification\n",
    "\n",
    "We will learn to classify phrases as Spanish or English.\n",
    "\n",
    "First, lets get all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([' AL DUQUE DE BÉJAR, marqués de Gibraleón, conde de Benalcázar y Bañares, vizconde de La Puebla de Alcocer, señor de las villas de Capilla, Curiel y Burguillos En fe del buen acogimiento y honra que hace Vuestra Excelencia a toda suerte de libros, como príncipe tan inclinado a favorecer las buenas artes, mayormente las que por su nobleza no se abaten al servicio y granjerías del vulgo, he determinado de sacar a luz al Ingenioso hidalgo don Quijote de la Mancha, al abrigo del clarísimo nombre de Vuestra Excelencia, a quien, con el acatamiento que debo a tanta grandeza, suplico le reciba agradablemente en su protección, para que a su sombra, aunque desnudo de aquel precioso ornamento de elegancia y erudición de que suelen andar vestidas las obras que se componen en las casas de los hombres que saben, ose parecer seguramente en el juicio de algunos que, continiéndose en los límites de su ignorancia, suelen condenar con más rigor y menos justicia los trabajos ajenos; que, poniendo los ojos la prudencia de Vuestra Excelencia en mi buen deseo, fío que no desdeñará la cortedad de tan humilde servicio',\n",
       "  ' Miguel de Cervantes Saavedra'],\n",
       " [' He looks out after a job, and puts plenty of energy into it while he is at it; in fact, so many different things has he done, that he says himself that it is easier to mention the things he has not done than the ones he has',\n",
       "  ' He has been an ordinary seaman, typewriter agent, a steamer-fireman, office-manager, hobo, farmhand, gold prospector, coach-driver, navvy, engine-driver, and many other things'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, re\n",
    "\n",
    "spanish_novels = ['http://www.gutenberg.org/cache/epub/2000/pg2000.txt']\n",
    "english_novels = ['https://www.gutenberg.org/files/46787/46787-0.txt']\n",
    "\n",
    "spanish_sentences = [s for novel in spanish_novels \n",
    "                     for s in re.sub(r'\\s+', ' ', requests.get(novel).text).split('.')[20:-20]]\n",
    "english_sentences = [s for novel in english_novels\n",
    "                     for s in re.sub(r'\\s+', ' ', requests.get(novel).text).split('.')[20:-20]]\n",
    "\n",
    "spanish_sentences[:2], english_sentences[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a new network for what we want,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd, sym\n",
    "from mxnet import gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastNet(gluon.Block):\n",
    "    def __init__(self, recurrent_width, forward_width, **kwargs):\n",
    "        super(LastNet, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self._rnn = gluon.rnn.LSTM(recurrent_width)\n",
    "            self._nn  = gluon.nn.Dense(forward_width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self._rnn(x)\n",
    "        return self._nn(h[h.shape[0]-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now prep the data and the network,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LIMIT = 100\n",
    "spanish_sentences, english_sentences = (list(filter(lambda s: len(s) > 0, spanish_sentences)),\n",
    "                                        list(filter(lambda s: len(s) > 0, english_sentences)))\n",
    "\n",
    "data = ([(s, 1) for s in spanish_sentences][:LIMIT] + \n",
    "        [(s, 0) for s in english_sentences][:LIMIT])\n",
    "\n",
    "\n",
    "ctx = mx.cpu()\n",
    "\n",
    "net = LastNet(100, 2)\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "net.collect_params().initialize(mx.init.Xavier(), ctx=ctx)\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': .1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin training,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\tLoss: 16.7151\n",
      "\tLoss: 20.8273\n",
      "\tLoss: 13.6166\n",
      "\tLoss: 14.0178\n",
      "\tLoss: 13.3715\n",
      "\tLoss: 13.7383\n",
      "\tLoss: 13.4944\n",
      "\tLoss: 14.0271\n",
      "\tLoss: 17.2844\n",
      "\tLoss: 17.6789\n",
      "Epoch 1\n",
      "\tLoss: 18.6013\n",
      "\tLoss: 18.5866\n",
      "\tLoss: 14.864\n",
      "\tLoss: 13.9156\n",
      "\tLoss: 14.0498\n",
      "\tLoss: 14.0009\n",
      "\tLoss: 12.9225\n",
      "\tLoss: 13.3744\n",
      "\tLoss: 14.7069\n",
      "\tLoss: 15.0635\n",
      "Epoch 2\n",
      "\tLoss: 13.5272\n",
      "\tLoss: 14.2686\n",
      "\tLoss: 14.0251\n",
      "\tLoss: 13.7333\n",
      "\tLoss: 15.5724\n",
      "\tLoss: 16.0863\n",
      "\tLoss: 13.9272\n",
      "\tLoss: 13.6959\n",
      "\tLoss: 13.5329\n",
      "\tLoss: 12.7551\n",
      "Epoch 3\n",
      "\tLoss: 15.1875\n",
      "\tLoss: 14.854\n",
      "\tLoss: 14.6476\n",
      "\tLoss: 14.1461\n",
      "\tLoss: 19.8791\n",
      "\tLoss: 12.1941\n",
      "\tLoss: 15.3345\n",
      "\tLoss: 13.9373\n",
      "\tLoss: 18.5974\n",
      "\tLoss: 13.9196\n",
      "Epoch 4\n",
      "\tLoss: 14.0716\n",
      "\tLoss: 13.4959\n",
      "\tLoss: 13.7474\n",
      "\tLoss: 15.7465\n",
      "\tLoss: 12.9978\n",
      "\tLoss: 13.941\n",
      "\tLoss: 14.4755\n",
      "\tLoss: 13.4096\n",
      "\tLoss: 14.3536\n",
      "\tLoss: 13.7129\n",
      "Epoch 5\n",
      "\tLoss: 13.6495\n",
      "\tLoss: 13.4973\n",
      "\tLoss: 13.348\n",
      "\tLoss: 13.5933\n",
      "\tLoss: 13.9643\n",
      "\tLoss: 12.9618\n",
      "\tLoss: 13.7921\n",
      "\tLoss: 13.6252\n",
      "\tLoss: 13.3976\n",
      "\tLoss: 13.2989\n",
      "Epoch 6\n",
      "\tLoss: 14.8015\n",
      "\tLoss: 15.3817\n",
      "\tLoss: 13.6578\n",
      "\tLoss: 13.5268\n",
      "\tLoss: 13.6315\n",
      "\tLoss: 13.8451\n",
      "\tLoss: 14.3097\n",
      "\tLoss: 12.644\n",
      "\tLoss: 15.1126\n",
      "\tLoss: 14.2021\n",
      "Epoch 7\n",
      "\tLoss: 12.4725\n",
      "\tLoss: 11.4768\n",
      "\tLoss: 15.3725\n",
      "\tLoss: 13.8945\n",
      "\tLoss: 13.0903\n",
      "\tLoss: 13.1057\n",
      "\tLoss: 15.6292\n",
      "\tLoss: 13.0715\n",
      "\tLoss: 14.1033\n",
      "\tLoss: 13.1646\n",
      "Epoch 8\n",
      "\tLoss: 16.0698\n",
      "\tLoss: 13.3924\n",
      "\tLoss: 13.4127\n",
      "\tLoss: 13.5536\n",
      "\tLoss: 13.4364\n",
      "\tLoss: 14.3313\n",
      "\tLoss: 14.3138\n",
      "\tLoss: 14.7297\n",
      "\tLoss: 13.4934\n",
      "\tLoss: 14.3178\n",
      "Epoch 9\n",
      "\tLoss: 13.8743\n",
      "\tLoss: 12.7016\n",
      "\tLoss: 13.4749\n",
      "\tLoss: 13.4223\n",
      "\tLoss: 13.6161\n",
      "\tLoss: 12.826\n",
      "\tLoss: 16.7459\n",
      "\tLoss: 13.6158\n",
      "\tLoss: 14.5501\n",
      "\tLoss: 12.0595\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=20\n",
    "for epoch in range(10):\n",
    "    print(\"Epoch\", epoch)\n",
    "    for batch in np.random.choice(len(data), size=(int(len(data)/BATCH_SIZE), BATCH_SIZE)):\n",
    "        with autograd.record():\n",
    "            loss = sum(softmax_cross_entropy(net(nd.array([ord(c) for c in data[i][0]]).reshape(shape=(-1, 1, 1))),\n",
    "                                             nd.array([data[i][1]]).reshape((-1, 1)))\n",
    "                       for i in batch)\n",
    "        loss.backward()\n",
    "        trainer.step(BATCH_SIZE)\n",
    "        print(\"\\tLoss:\", loss.asscalar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " He looks out after a job, and ... [ 0.66601664  0.33398333]\n",
      " He has been an ordinary seama ... [ 0.66173398  0.33826602]\n",
      " And strangely enough, though  ... [ 0.65979099  0.34020898]\n",
      " Before this present War, he w ... [ 0.65617484  0.34382516]\n",
      " At the outbreak of hostilitie ... [ 0.66291416  0.33708584]\n",
      " It was his experience as “For ... [ 0.66168475  0.33831525]\n",
      "” In this dangerous and respon ... [ 0.65999079  0.34000921]\n",
      " On one occasion, for instance ... [ 0.66685075  0.33314925]\n",
      " After eighteen months of this ... [ 0.65578395  0.34421599]\n",
      " Boyd Cable was naturally disg ... [ 0.66238678  0.33761325]\n",
      " As may be remembered, the Bri ... [ 0.66744977  0.33255026]\n",
      "” The following letter has jus ... [ 0.65290487  0.34709516]\n",
      " Boyd Cable by the publishers, ... [ 0.66605604  0.33394399]\n",
      " They feel that it will give t ... [ 0.66070402  0.33929595]\n",
      " “ ... [ 0.60131729  0.39868271]\n",
      " Many thanks for all the troub ... [ 0.65624148  0.34375852]\n",
      " It certainly is odd that Brit ... [ 0.64949811  0.35050192]\n",
      " S ... [ 0.57908428  0.42091572]\n",
      " A ... [ 0.58392626  0.41607368]\n",
      " are not more interested in th ... [ 0.64870656  0.3512935 ]\n"
     ]
    }
   ],
   "source": [
    "for s in english_sentences[:20]:\n",
    "    if len(s) > 0:\n",
    "        x = nd.array([ord(c) for c in s]).reshape(shape=(-1, 1, 1))\n",
    "        pred = net(x)\n",
    "        pk = nd.exp(pred)/nd.sum(nd.exp(pred))\n",
    "        print(s[:30], '...', pk.asnumpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AL DUQUE DE BÉJAR, marqués de ... [ 0.67326111  0.32673883]\n",
      " Miguel de Cervantes Saavedra ... [ 0.6429202   0.35707983]\n",
      " PRÓLOGO Desocupado lector: si ... [ 0.6637482  0.3362518]\n",
      " Pero no he podido yo contrave ... [ 0.65791422  0.34208578]\n",
      " Y así, ¿qué podrá engendrar e ... [ 0.67113799  0.32886204]\n",
      " Acontece tener un padre un hi ... [ 0.66666156  0.33333847]\n",
      " Pero yo, que, aunque parezco  ... [ 0.67033619  0.32966381]\n",
      " Todo lo cual te esenta y hace ... [ 0.6655066   0.33449343]\n",
      " Sólo quisiera dártela monda y ... [ 0.66323876  0.33676127]\n",
      " Porque te sé decir que, aunqu ... [ 0.65945518  0.34054479]\n",
      " Muchas veces tomé la pluma pa ... [ 0.67230719  0.32769284]\n",
      " -Porque, ¿cómo queréis vos qu ... [ 0.67159802  0.32840198]\n",
      " De todo esto ha de carecer mi ... [ 0.66077638  0.33922359]\n",
      "B ... [ 0.54020214  0.45979792]\n",
      "C ... [ 0.54010892  0.45989111]\n",
      ", comenzando en Aristóteles y  ... [ 0.65737915  0.34262085]\n",
      " También ha de carecer mi libr ... [ 0.66847938  0.33152056]\n",
      " En fin, señor y amigo mío -pr ... [ 0.66830146  0.33169851]\n",
      " De aquí nace la suspensión y  ... [ 0.65841961  0.34158039]\n",
      " Oyendo lo cual mi amigo, dánd ... [ 0.66950238  0.33049762]\n"
     ]
    }
   ],
   "source": [
    "for s in spanish_sentences[:20]:\n",
    "    if len(s) > 0:\n",
    "        x = nd.array([ord(c) for c in s]).reshape(shape=(-1, 1, 1))\n",
    "        pred = net(x)\n",
    "        pk = nd.exp(pred)/nd.sum(nd.exp(pred))\n",
    "        print(s[:30], '...', pk.asnumpy().flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
